{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inbalanced Classes\n",
    "## In this lab, we are going to explore a case of imbalanced classes. \n",
    "\n",
    "\n",
    "Like we disussed in class, when we have noisy data, if we are not careful, we can end up fitting our model to the noise in the data and not the 'signal'-- the factors that actually determine the outcome. This is called overfitting, and results in good results in training, and in bad results when the model is applied to real data. Similarly, we could have a model that is too simplistic to accurately model the signal. This produces a model that doesnt work well (ever). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, download the data from: https://www.kaggle.com/ntnu-testimon/paysim1. Import the dataset and provide some discriptive statistics and plots. What do you think will be the important features in determining the outcome?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.\n",
    "\n",
    "data=pd.read_csv('/Users/abc/Desktop/vehicles/PS_20174392719_1491204439457_log.csv')\n",
    "\n",
    "data.head()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the distribution of the outcome? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# data['isFraud'].hist()\n",
    "\n",
    "\n",
    "# data['isFraud'].plot(kind='bar')\n",
    "\n",
    "sns.countplot(x='isFraud',data=data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the dataset. How are you going to integrate the time variable? Do you think the step (integer) coding in which it is given is appropriate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  step - maps a unit of time in the real world. In this case 1 step is 1 hour of time. Total steps 744 (30 days simulation).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a logisitc regression classifier and evaluate its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "X = website[website.columns.difference([['isFraud','isFlaggedFraud']])\n",
    "y = website['isFraud']                                 \n",
    "test_size=0.2\n",
    "                                       \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=test_size)\n",
    "                                       \n",
    "y_test_pred=model.predict(X_test)  \n",
    "confusion_matrix(y_test,y_pred_test)\n",
    "matrix = confusion_matrix(y_test, y_test_pred)   \n",
    "accuracy = model.score(X_test,y_test)\n",
    "            \n",
    "            \n",
    "print('Confusion Matrix:\\n',matrix)             \n",
    "print('Accuracy accuracy is:', accuracy)  \n",
    "\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now pick a model of your choice and evaluate its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model2 = DecisionTreeClassifier(criterion = 'entropy' , random_state=42).fit(X_train, y_train)\n",
    "\n",
    "y_test_pred2 = model2.predict(X_test)\n",
    "matrix  = confusion_matrix(y_test, y_test_pred2)\n",
    "accuracy = model.score(X_test,y_test)\n",
    "\n",
    "print('Confusion Matrix:\\n',matrix)             \n",
    "print('Accuracy accuracy is:', accuracy)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which model worked better and how do you know?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your response here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
